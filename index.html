<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>rizma</title>
</head>
<body style="font-family:-apple-system, BlinkMacSystemFont, 'SF Pro Text', 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; background:#FFFFFF; color:#0E0E10; display:flex; flex-direction:column; align-items:center; gap:24px; min-height:100vh; margin:0;">
  <!-- Header / Brand -->
  <header style="margin-top:40px; display:flex; flex-direction:column; align-items:center; gap:8px;">
    <div style="display:flex; align-items:center; gap:10px;">
      <img src="rizma_logo_color.png" alt="rizma logo" style="width:36px; height:36px; box-shadow:0 1px 2px rgba(0,0,0,0.06);" />
      <div style="font-size:28px; font-weight:700; letter-spacing:0.2px;">rizma</div>
    </div>
    <div style="font-size:16px; color:#6B6B6B;">Support Between Sessions</div>
  </header>

  <!-- Therapist Card -->
  <section style="width:min(760px, calc(100% - 48px)); background:#FFFFFF; border:1px solid #EEE; border-radius:20px; padding:32px; box-shadow:0 8px 24px rgba(0,0,0,0.05); display:flex; flex-direction:column; align-items:center; gap:16px;">
    <img src="rizma-doc-3-elena_cropped.png" alt="Elena" style="width:120px; height:120px; border-radius:60px; object-fit:cover; box-shadow:0 2px 6px rgba(0,0,0,0.06);" />
    <div style="font-size:28px; font-weight:700;">Elena</div>
    <div style="font-size:16px; color:#6B6B6B; text-align:center; max-width:520px;">Helps with homework and answers questions.</div>
    <button id="hold" aria-pressed="false" style="font-size:18px; font-weight:600; padding:16px 24px; border-radius:14px; background:#FBD5C7; color:#0E0E10; border:none; width:100%; max-width:420px; box-shadow:0 2px 6px rgba(0,0,0,0.06);">
      Start Voice Session
    </button>
  </section>

  <!-- Conversation Panel -->
  <section id="panel" style="width:min(760px, calc(100% - 48px)); background:#FFFFFF; color:#0E0E10; border:1px solid #EEE; border-radius:16px; padding:12px 16px; box-shadow:0 4px 14px rgba(0,0,0,0.04);">
    <div id="status" style="font-size:12px; opacity:0.7; margin-bottom:8px;">Idle</div>
    <div id="chat" style="display:flex; flex-direction:column; gap:8px; max-height:40vh; overflow:auto; padding-right:6px;"></div>
  </section>

  <!-- Footer -->
  <footer style="margin:8px 0 24px; color:#8B8B8B; font-size:14px; display:flex; gap:8px; align-items:center;">
    <span>Secure &bull; Private &bull; Professional</span>
    <button id="reset" style="margin-left:12px; font-size:12px; color:#6B6B6B; background:transparent; border:none; text-decoration:underline; cursor:pointer;">Reset Session</button>
  </footer>

  <script>
    // OpenAI key stays in Cloudflare Worker secret; browser calls proxy
    const API_BASE = "https://rizma-proxy.rizma.workers.dev/openai";

    let mediaRecorder, chunks = [];
    let isRecording = false;
    let recStartedAt = 0;
    let hasSessionStarted = false; // tracks whether we've recorded at least once

    const btn = document.getElementById('hold');
    const statusEl = document.getElementById('status');
    const chatEl = document.getElementById('chat');

    // --- Conversation memory (rolling window + running summary persisted to localStorage) ---
    const SYSTEM_PROMPT = "You are Elena, an empathetic assistant. The length of your response should match the topic and the need for details. No need for fluff but provide in-depth response or guidance if needed. Validate feelings, avoid diagnoses or crisis guidance. Be concise and warm.";

    const MEMORY_KEY = "rizma_memory_v1";
    const MAX_TURNS_TO_SEND = 6; // send at most last 6 user+assistant exchanges (12 messages)

    let memory = {
      summary: "",                 // running summary string
      messages: []                 // full chronological list of {role:'user'|'assistant', content:string}
    };

    function saveMemory() {
      try { localStorage.setItem(MEMORY_KEY, JSON.stringify({ summary: memory.summary, messages: memory.messages })); } catch {}
    }

    function loadMemory() {
      try {
        const raw = localStorage.getItem(MEMORY_KEY);
        if (!raw) return;
        const data = JSON.parse(raw);
        memory.summary = data.summary || "";
        memory.messages = Array.isArray(data.messages) ? data.messages : [];
      } catch {}
    }

    function clearMemory() {
      memory.summary = "";
      memory.messages = [];
      saveMemory();
      if (chatEl) chatEl.innerHTML = "";
      hasSessionStarted = false;
      setBtnRecordingUI(false);
      if (statusEl) statusEl.textContent = "Idle";
    }

    function renderHistory() {
      if (!chatEl || !memory.messages.length) return;
      chatEl.innerHTML = "";
      for (const m of memory.messages) {
        addMessage(m.content, m.role === 'user' ? 'user' : 'elena');
      }
    }

    // Build the message array we send to the model: system + summary + recent turns + new user text
    function buildMessages(userText) {
      const msgs = [{ role: "system", content: SYSTEM_PROMPT }];
      if (memory.summary) {
        msgs.push({ role: "system", content: "Conversation summary so far:\n" + memory.summary });
      }
      const recentTurns = memory.messages.slice(-MAX_TURNS_TO_SEND * 2); // user+assistant pairs
      msgs.push(...recentTurns);
      msgs.push({ role: "user", content: userText });
      return msgs;
    }

    // Periodically compress older turns into the running summary
    async function maybeSummarize() {
      const LIMIT = MAX_TURNS_TO_SEND * 2;
      if (memory.messages.length <= LIMIT) return;

      // Everything except the last LIMIT messages gets summarized
      const toSummarize = memory.messages.slice(0, memory.messages.length - LIMIT);
      const contextText = toSummarize.map(m => `${m.role.toUpperCase()}: ${m.content}`).join("\n\n");

      const r = await fetch(`${API_BASE}/chat/completions`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          model: "gpt-4o-mini",
          messages: [
            { role: "system", content: "Summarize the conversation so far in 120-180 words. Capture facts, preferences, goals, and open questions. Output plain text only." },
            { role: "user", content: `Existing summary:\n${memory.summary || "(none)"}\n\nNew dialogue to fold in:\n${contextText}` }
          ]
        })
      });
      if (r.ok) {
        const j = await r.json();
        const newSummary = j.choices?.[0]?.message?.content || "";
        if (newSummary) {
          memory.summary = newSummary.trim();
          // Drop the summarized messages; keep only the last LIMIT
          memory.messages = memory.messages.slice(-LIMIT);
          saveMemory();
        }
      }
    }

    // Load from localStorage on startup and render any prior history
    loadMemory();
    renderHistory();
    // --- End conversation memory ---

    // --- Adaptive controls: desktop = click/keyboard toggle; mobile = press-and-hold ---
    function setBtnRecordingUI(rec) {
      btn.setAttribute('aria-pressed', rec ? 'true' : 'false');
      const label = rec ? 'Stop Recording' : (hasSessionStarted ? 'Start Recording' : 'Start Voice Session');
      btn.textContent = label;
      // subtle state color shift
      btn.style.background = rec ? '#F7C2B0' : '#FBD5C7';
    }

    function isTouchDevice() {
      return (window.matchMedia && window.matchMedia('(pointer: coarse)').matches) || (navigator.maxTouchPoints > 0);
    }

    function handleClickToggle(e) {
      e && e.preventDefault();
      if (!isRecording) {
        startRec();
        setBtnRecordingUI(true);
      } else {
        stopRec();
        setBtnRecordingUI(false);
      }
    }

    function handleKeyToggle(e) {
      // Space or Enter toggles on desktop
      if (e.key === ' ' || e.key === 'Spacebar' || e.key === 'Enter') {
        e.preventDefault();
        handleClickToggle(e);
      }
    }

    function handlePointerDown(e) {
      e.preventDefault();
      if (!isRecording) {
        startRec();
        setBtnRecordingUI(true);
      }
    }

    function handlePointerUp(e) {
      e && e.preventDefault();
      if (isRecording) {
        stopRec();
        setBtnRecordingUI(false);
      }
    }

    function bindControls() {
      if (isTouchDevice()) {
        // mobile/tablet: press-and-hold
        btn.style.touchAction = 'none';
        btn.addEventListener('pointerdown', handlePointerDown, { passive: false });
        btn.addEventListener('pointerup', handlePointerUp, { passive: false });
        btn.addEventListener('pointercancel', handlePointerUp);
        btn.addEventListener('pointerleave', (e) => { if (e.buttons === 0) handlePointerUp(e); });
      } else {
        // desktop: click or keyboard to toggle
        btn.addEventListener('click', handleClickToggle);
        document.addEventListener('keydown', handleKeyToggle);
      }
    }
    bindControls();
    // --- End adaptive controls ---

    function addMessage(text, sender) {
      if (!chatEl) return;
      const row = document.createElement('div');
      row.style.display = 'flex';
      row.style.justifyContent = sender === 'user' ? 'flex-end' : 'flex-start';
      const bubble = document.createElement('div');
      bubble.textContent = (text || '').trim();
      bubble.style.maxWidth = '80%';
      bubble.style.padding = '10px 12px';
      bubble.style.border = 'none';
      bubble.style.borderRadius = '12px';
      bubble.style.whiteSpace = 'pre-wrap';
      bubble.style.wordBreak = 'break-word';
      // Colors: user on right = lighter peach, Elena on left = very light gray
      if (sender === 'user') {
        bubble.style.background = '#FFE6DE';   // lighter peach
      } else {
        bubble.style.background = '#F5F5F5';   // very light gray for Elena
      }
      row.appendChild(bubble);
      chatEl.appendChild(row);
      chatEl.scrollTop = chatEl.scrollHeight;
    }

    async function startRec() {
      if (isRecording) return;
      if (statusEl) statusEl.textContent = 'Listening...';

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // Choose a supported mime
        let mime = "";
        if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) mime = "audio/webm;codecs=opus";
        else if (MediaRecorder.isTypeSupported("audio/webm")) mime = "audio/webm";
        else if (MediaRecorder.isTypeSupported("audio/ogg;codecs=opus")) mime = "audio/ogg;codecs=opus";
        else if (MediaRecorder.isTypeSupported("audio/ogg")) mime = "audio/ogg";

        mediaRecorder = new MediaRecorder(stream, mime ? { mimeType: mime } : undefined);
        chunks = [];
        isRecording = true;
        recStartedAt = Date.now();
        hasSessionStarted = true;

        mediaRecorder.ondataavailable = (e) => { if (e.data && e.data.size) chunks.push(e.data); };

        mediaRecorder.onstop = async () => {
          try {
            const type = mediaRecorder.mimeType || "audio/webm";
            const ext  = type.includes("ogg") ? "ogg" : "webm";
            const blob = new Blob(chunks, { type });
            if (!blob.size) throw new Error("Empty recording blob");

            const file = new File([blob], `input.${ext}`, { type });

            const transcript = await stt(file);
            addMessage(transcript || '(no speech detected)', 'user');
            // persist user turn
            memory.messages.push({ role: 'user', content: transcript || '' });
            saveMemory();
            if (statusEl) statusEl.textContent = 'Thinking...';

            const reply = await llm(buildMessages(transcript || ''));
            addMessage(reply || '', 'elena');
            // persist assistant turn
            memory.messages.push({ role: 'assistant', content: reply || '' });
            saveMemory();
            // compress old turns if needed
            await maybeSummarize();

            if (statusEl) statusEl.textContent = 'Replying...';
            const audioBlob = await tts(reply);
            const url = URL.createObjectURL(audioBlob);
            const audio = new Audio(url);
            await audio.play().catch(e => console.error('Audio play error:', e));
          } catch (err) {
            console.error("Pipeline error:", err);
          } finally {
            mediaRecorder.stream.getTracks().forEach(t => t.stop());
            if (statusEl) statusEl.textContent = 'Idle';
            isRecording = false;
          }
        };

        mediaRecorder.start(100); // timeslice so short presses still yield chunks
      } catch (e) {
        console.error("getUserMedia error:", e);
        // revert UI if permission or device fails
        setBtnRecordingUI(false);
      }
    }

    function stopRec() {
      if (!isRecording || !mediaRecorder) return;
      const MIN_MS = 300;
      const elapsed = Date.now() - recStartedAt;
      const wait = Math.max(0, MIN_MS - elapsed);
      setTimeout(() => {
        if (mediaRecorder && mediaRecorder.state === "recording") {
          mediaRecorder.stop();
        }
      }, wait);
    }

    async function stt(file) {
      const fd = new FormData();
      fd.append("file", file, file.name);
      fd.append("model", "gpt-4o-transcribe"); // or "whisper-1"
      fd.append("language", "en");
      const r = await fetch(`${API_BASE}/audio/transcriptions`, { method: "POST", body: fd });
      if (!r.ok) { throw new Error(await r.text()); }
      const j = await r.json();
      return j.text || "";
    }

    async function llm(messages) {
      const r = await fetch(`${API_BASE}/chat/completions`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          model: "gpt-5",
          messages,
          max_tokens: 1200,
          temperature: 0.7
        })
      });
      if (!r.ok) throw new Error(await r.text());
      const j = await r.json();
      return j.choices?.[0]?.message?.content || "";
    }

    async function tts(text) {
      const r = await fetch(`${API_BASE}/audio/speech`, {
        method: "POST",
        headers: { "Content-Type": "application/json", Accept: "audio/mpeg" },
        body: JSON.stringify({ model: "tts-1-hd-1106", voice: "alloy", input: text, format: "mp3" })
      });
      if (!r.ok) throw new Error(await r.text());
      const buf = await r.arrayBuffer();
      return new Blob([buf], { type: "audio/mpeg" });
    }

    // Reset Session clears memory and UI
    const resetBtn = document.getElementById('reset');
    if (resetBtn) {
      resetBtn.addEventListener('click', () => {
        clearMemory();
      });
    }
  </script>
</body>
 </html>