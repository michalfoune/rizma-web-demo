<!doctype html>
<html>

<head>
  <!-- classic fallback -->
  <link rel="icon" href="/favicon.ico" sizes="any">

  <!-- modern PNGs -->
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16.png">
</head>

<body
  style="font-family:sans-serif;background:#FBD5C7;color:#0E0E10;display:flex;flex-direction:column;align-items:center;justify-content:center;gap:16px;height:100vh">
  <button id="hold"
    style="font-size:18px;padding:18px 28px;border-radius:12px;background:#FFFFFF;border:1px solid #0E0E10">
    Hold to Speak
  </button>
  <div id="panel" style="max-width:800px; width:calc(100% - 48px); margin:12px auto 0; background:#FFFFFF; color:#0E0E10; border:1px solid #0E0E10; border-radius:12px; padding:12px 16px;">
    <div id="status" style="font-size:12px; opacity:0.7; margin-bottom:8px;">Idle</div>
    <div id="chat" style="display:flex; flex-direction:column; gap:8px; max-height:40vh; overflow:auto; padding-right:6px;"></div>
  </div>
  <script>
    // OpenAI key stays in Cloudflare Worker secret; browser calls proxy
    const API_BASE = "https://rizma-proxy.rizma.workers.dev/openai";

    let mediaRecorder, chunks = [];
    let isRecording = false;
    let recStartedAt = 0;

    const btn = document.getElementById('hold');
    const statusEl = document.getElementById('status');
    const chatEl = document.getElementById('chat');

    function addMessage(text, sender) {
      if (!chatEl) return;
      const row = document.createElement('div');
      row.style.display = 'flex';
      row.style.justifyContent = sender === 'user' ? 'flex-end' : 'flex-start';
      const bubble = document.createElement('div');
      bubble.textContent = (text || '').trim();
      bubble.style.maxWidth = '80%';
      bubble.style.padding = '10px 12px';
      bubble.style.border = 'none';
      bubble.style.borderRadius = '12px';
      bubble.style.whiteSpace = 'pre-wrap';
      bubble.style.wordBreak = 'break-word';
      // Colors: user on right = lighter peach, Elena on left = very light gray
      if (sender === 'user') {
        bubble.style.background = '#FFE6DE';   // lighter peach
      } else {
        bubble.style.background = '#F5F5F5';   // very light gray for Elena
      }
      row.appendChild(bubble);
      chatEl.appendChild(row);
      chatEl.scrollTop = chatEl.scrollHeight;
    }

    btn.onmousedown = startRec;
    btn.onmouseup = stopRec;

    async function startRec() {
      if (isRecording) return;
      if (statusEl) statusEl.textContent = 'Listening...';

      // 1) Request mic (Chrome on http://localhost)
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // 2) Choose a supported mime
        let mime = "";
        if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) mime = "audio/webm;codecs=opus";
        else if (MediaRecorder.isTypeSupported("audio/webm")) mime = "audio/webm";
        else if (MediaRecorder.isTypeSupported("audio/ogg;codecs=opus")) mime = "audio/ogg;codecs=opus";
        else if (MediaRecorder.isTypeSupported("audio/ogg")) mime = "audio/ogg";

        mediaRecorder = new MediaRecorder(stream, mime ? { mimeType: mime } : undefined);
        chunks = [];
        isRecording = true;
        recStartedAt = Date.now();

        mediaRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size) chunks.push(e.data);
        };

        mediaRecorder.onstop = async () => {
          try {
            // Build a proper File for the API
            const type = mediaRecorder.mimeType || "audio/webm";
            const ext = type.includes("ogg") ? "ogg" : "webm";
            const blob = new Blob(chunks, { type });
            if (!blob.size) throw new Error("Empty recording blob");

            const file = new File([blob], `input.${ext}`, { type });

            const transcript = await stt(file);
            // show the user's transcribed text as a right-aligned bubble
            addMessage(transcript || '(no speech detected)', 'user');
            if (statusEl) statusEl.textContent = 'Thinking...';

            const reply = await llm(transcript);
            // show Elena's reply as a left-aligned bubble
            addMessage(reply || '', 'elena');
            if (statusEl) statusEl.textContent = 'Replying...';

            const audioBlob = await tts(reply);

            const url = URL.createObjectURL(audioBlob);
            const audio = new Audio(url);
            await audio.play();
          } catch (err) {
            console.error("Pipeline error:", err);
          } finally {
            // stop mic
            mediaRecorder.stream.getTracks().forEach(t => t.stop());
            if (statusEl) statusEl.textContent = 'Idle';
            isRecording = false;
          }
        };

        // Timeslice ensures data available fires even for short presses
        mediaRecorder.start(100);
      } catch (e) {
        console.error("getUserMedia error:", e);
        // If no prompt: check Chrome Site Settings -> Mic, and macOS Settings -> Privacy & Security -> Microphone
      }
    }

    function stopRec() {
      if (!isRecording || !mediaRecorder) return;

      // 3) Ensure minimum duration before stopping (>= 0.3 s > serverâ€™s 0.1 s floor)
      const MIN_MS = 300;
      const elapsed = Date.now() - recStartedAt;
      const wait = Math.max(0, MIN_MS - elapsed);

      setTimeout(() => {
        if (mediaRecorder && mediaRecorder.state === "recording") {
          // If you want, you can flush one last chunk *before* stop:
          // mediaRecorder.requestData();   // safe here, still "recording"
          mediaRecorder.stop();
        }
      }, wait);
    }

    // 4) STT sends a File and forces English
    async function stt(file) {
      const fd = new FormData();
      fd.append("file", file, file.name);
      fd.append("model", "gpt-4o-transcribe"); // "whisper-1" 
      fd.append("language", "en");

      const r = await fetch(`${API_BASE}/audio/transcriptions`, {
        method: "POST",
        body: fd
      });
      if (!r.ok) {
        const err = await r.text();
        console.error("STT failed:", r.status, err);
        throw new Error(err);
      }
      const j = await r.json();
      return j.text || "";
    }

    async function llm(text) {
      const r = await fetch(`${API_BASE}/chat/completions`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          model: "gpt-4o",
          messages: [
            { role: "system", content: "You are warm and concise. The length of the response should match the depth of the topic." },
            { role: "user", content: text }
          ]
        })
      });
      if (!r.ok) throw new Error(await r.text());
      const j = await r.json();
      return j.choices?.[0]?.message?.content || "";
    }

    async function tts(text) {
      const r = await fetch(`${API_BASE}/audio/speech`, {
        method: "POST",
        headers: { "Content-Type": "application/json", Accept: "audio/mpeg" },
        body: JSON.stringify({ model: "tts-1-hd-1106", voice: "alloy", input: text, format: "mp3" })
      });
      if (!r.ok) throw new Error(await r.text());
      const buf = await r.arrayBuffer();
      return new Blob([buf], { type: "audio/mpeg" });
    }
  </script>

</body>

</html>